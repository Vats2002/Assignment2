{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Create a SparkContext\n",
    "sc = SparkContext(appName=\"RDDExample\")\n",
    "\n",
    "# Create an RDD from a local data source (a list)\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# Apply transformations and actions on the RDD\n",
    "# Example transformations: map, filter\n",
    "squared_rdd = rdd.map(lambda x: x**2)\n",
    "filtered_rdd = squared_rdd.filter(lambda x: x > 10)\n",
    "\n",
    "# Example actions: reduce, collect\n",
    "sum_of_squares = squared_rdd.reduce(lambda x, y: x + y)\n",
    "collected_data = filtered_rdd.collect()\n",
    "\n",
    "# Analyze and manipulate data using RDD operations\n",
    "print(\"Squared RDD:\", squared_rdd.collect())\n",
    "print(\"Filtered RDD:\", collected_data)\n",
    "print(\"Sum of squares:\", sum_of_squares)\n",
    "\n",
    "# Close the SparkContext\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrameExample\").getOrCreate()\n",
    "\n",
    "# Load a CSV file into a Spark DataFrame\n",
    "df = spark.read.csv(\"path/to/your/csv/file.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Perform common DataFrame operations\n",
    "# Example filtering\n",
    "filtered_df = df.filter(df[\"age\"] > 30)\n",
    "\n",
    "# Example grouping and aggregation\n",
    "grouped_df = df.groupBy(\"gender\").agg({\"salary\": \"avg\"})\n",
    "\n",
    "# Example joining\n",
    "other_df = spark.read.csv(\"path/to/another/csv/file.csv\", header=True, inferSchema=True)\n",
    "joined_df = df.join(other_df, df[\"id\"] == other_df[\"id\"], \"inner\")\n",
    "\n",
    "# Apply Spark SQL queries on the DataFrame\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "sql_query = \"SELECT * FROM people WHERE age > 30\"\n",
    "sql_result = spark.sql(sql_query)\n",
    "\n",
    "# Display the DataFrame and SQL results\n",
    "df.show()\n",
    "filtered_df.show()\n",
    "grouped_df.show()\n",
    "joined_df.show()\n",
    "sql_result.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "# Create a Spark Streaming Context\n",
    "spark_streaming_context = StreamingContext(sparkContext, batchDuration)\n",
    "\n",
    "# Configure the application to consume data from a streaming source (e.g., Kafka or a socket)\n",
    "kafka_params = {\n",
    "    'bootstrap.servers': 'localhost:9092',  # Replace with your Kafka broker addresses\n",
    "    'group.id': 'your_consumer_group'  # Replace with your consumer group ID\n",
    "}\n",
    "\n",
    "# Create a DStream by consuming from a Kafka topic\n",
    "kafka_topic = 'your_topic'  # Replace with the desired topic name\n",
    "kafka_stream = KafkaUtils.createDirectStream(\n",
    "    spark_streaming_context, [kafka_topic], kafka_params\n",
    ")\n",
    "\n",
    "# Implement streaming transformations and actions to process and analyze the incoming data stream\n",
    "# Example streaming transformations: map, filter\n",
    "processed_stream = kafka_stream.map(lambda message: message[1].upper()).filter(lambda word: word.startswith('A'))\n",
    "\n",
    "# Example streaming actions: count\n",
    "word_count = processed_stream.count()\n",
    "\n",
    "# Print the results\n",
    "word_count.pprint()\n",
    "\n",
    "# Start the streaming context\n",
    "spark_streaming_context.start()\n",
    "\n",
    "# Wait for the streaming to finish\n",
    "spark_streaming_context.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkSQLExample\").getOrCreate()\n",
    "\n",
    "# Connect Spark with a relational database (e.g., MySQL, PostgreSQL)\n",
    "jdbc_url = \"jdbc:mysql://localhost:3306/your_database\"  # Replace with your database connection URL\n",
    "connection_properties = {\n",
    "    \"user\": \"your_username\",  # Replace with your database username\n",
    "    \"password\": \"your_password\",  # Replace with your database password\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"  # Replace with the appropriate JDBC driver\n",
    "}\n",
    "\n",
    "# Read data from a database table using Spark SQL\n",
    "table_name = \"your_table\"  # Replace with the name of your database table\n",
    "df = spark.read.format(\"jdbc\").options(\n",
    "    url=jdbc_url,\n",
    "    dbtable=table_name,\n",
    "    **connection_properties\n",
    ").load()\n",
    "\n",
    "# Perform SQL operations on the data stored in the database using Spark SQL\n",
    "df.createOrReplaceTempView(\"my_table\")  # Create a temporary view for the DataFrame\n",
    "sql_query = \"SELECT * FROM my_table WHERE age > 30\"  # Replace with your SQL query\n",
    "sql_result = spark.sql(sql_query)\n",
    "\n",
    "# Display the SQL result\n",
    "sql_result.show()\n",
    "\n",
    "# Explore Spark's integration capabilities with other data sources, such as HDFS or Amazon S3\n",
    "hdfs_path = \"hdfs://localhost:9000/your_hdfs_file\"  # Replace with your HDFS file path\n",
    "df_hdfs = spark.read.text(hdfs_path)\n",
    "df_hdfs.show()\n",
    "\n",
    "s3_path = \"s3://your_bucket/your_s3_file\"  # Replace with your Amazon S3 file path\n",
    "df_s3 = spark.read.text(s3_path)\n",
    "df_s3.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
